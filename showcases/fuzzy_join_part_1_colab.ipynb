{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-colab"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/pathwaycom/pathway-examples/blob/main/showcases/fuzzy_join_part_1_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" class=\"inline\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "colab-instructions"
   },
   "source": [
    "# [Colab-specific] Setting up Python and Pathway\n",
    "\n",
    "> Colab heads-up!!!\n",
    ">\n",
    "> Pathway requires Python >=3.8 and works best with Python 3.10, while Google Colab ships with Python 3.7 by default.\n",
    ">\n",
    "> In the cells below we install Python 3.10 and then switch to it, but the process requires that you refresh the page in your browser!\n",
    "> Please:\n",
    "> 1. Run the first cell, disregard the unrecognized runtime warning.\n",
    "> 2. Refresh the colab page and rerun the notebook. Now the warning should disappear and the python version in cell #2 should be Python 3.10.\n",
    "\n",
    "\n",
    "Outside Colab, Pathway can be installed to a Python 3.10 environment using pip, please register at https://pathway.com to get beta access to the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pip-package-selection"
   },
   "outputs": [],
   "source": [
    "PIP_PACKAGE_ADDRESS=\"\"\n",
    "if not PIP_PACKAGE_ADDRESS:\n",
    "    print(\n",
    "        \"Please register at https://pathway.com/developers/documentation/introduction/installation-and-first-steps\\n\"\n",
    "        \"To get the pip package installation link!\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "colab-env-install",
    "outputId": "30a3baa7-5cb4-40f5-ac12-921eba4b25f8"
   },
   "outputs": [],
   "source": [
    "![ -d /usr/local/lib/python3.10/site-packages/pathway ] || echo \"Installing Python 3.10 and pathway, restart the notebook once this cells executes\"\n",
    "![ -d /usr/local/lib/python3.10/site-packages/pathway ] || wget -O mini.sh https://github.com/conda-forge/miniforge/releases/download/22.9.0-1/Mambaforge-22.9.0-1-Linux-x86_64.sh 1>/dev/null 2>/dev/null\n",
    "![ -d /usr/local/lib/python3.10/site-packages/pathway ] || chmod +x mini.sh 1>/dev/null 2>/dev/null\n",
    "![ -d /usr/local/lib/python3.10/site-packages/pathway ] || bash ./mini.sh -b -f -p /usr/local 1>/dev/null 2>/dev/null\n",
    "![ -d /usr/local/lib/python3.10/site-packages/pathway ] || mamba install -q -y -c conda-forge jupyter google-colab  1>/dev/null 2>/dev/null\n",
    "![ -d /usr/local/lib/python3.10/site-packages/pathway ] || python -m ipykernel install --name \"py310\" --user 1>/dev/null 2>/dev/null\n",
    "![ -d /usr/local/lib/python3.10/site-packages/pathway ] || pip install {PIP_PACKAGE_ADDRESS} 1>/dev/null 2>/dev/null\n",
    "![ -d /usr/local/lib/python3.10/site-packages/pathway ] && echo \"Pathway installed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "colab-reload",
    "outputId": "f0e45a04-0b52-4699-fd04-680980f3df92"
   },
   "outputs": [],
   "source": [
    "# Reload the web page and execute this cell\n",
    "import sys\n",
    "print(\"User Current Version:-\", sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "incorrectly_encoded_metadata": "jp-MarkdownHeadingCollapsed=true",
    "tags": []
   },
   "source": [
    "# Realtime Fuzzy-Join in Pathway\n",
    "\n",
    "## Part 1: Fuzzy joins: 'errare humanum est'\n",
    "\n",
    "As the ancient maxim says, ['errare humanum est'](https://en.wiktionary.org/w/index.php?title=errare_humanum_est): to err is human.\n",
    "More than two thousands years later, this lesson is still very accurate in our modern world.\n",
    "Everyone makes mistakes and writing does not escape this fate: the longer the text the more mistakes there will be.\n",
    "However, most mistakes we usually make are small and do not hinder understanding.\n",
    "\n",
    "Unfortunately, computers, just like accountants, don't like mistakes. Computers cannot cope with mistakes. No matter how small the mistake, the computer will just reject the whole answer and throw an error.\n",
    "You have written your 10-digit password but finished with a lower case 'a' instead of a capital 'A'? The passwords obviously do not match, and you shall enter your password again!\n",
    "\n",
    "While this zero tolerance policy may make sense for security processes, it can be terrible when users have to enter long texts.\n",
    "For example, accountants may have to enter long logs of transactions by hand, creating many opportunities for mistakes.\n",
    "If those logs have to be compared to other logs (e.g. a log automatically generated by a pay station) then mismatches would appear: 'mr' instead of 'Mr'.\n",
    "Mistakes can also come from the way the data has been collected: using nicknames instead of full names, different email addresses etc.\n",
    "While humans could be able to match those logs despite the mistakes, computers cannot.\n",
    "\n",
    "Does it mean the computer is helpless in those cases, shifting all the tedious work of matching similar but different entries to human?\n",
    "Fortunately not, several mechanisms exist to assist or even perform the matching, and **fuzzy join** is one of them: a fuzzy join is process which automatically matches entries from different logs despite not having a perfect matching between their keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fuzzy join in Pathway\n",
    "\n",
    "Fuzzy join is used to perform a join on datasets when the keys do not match exactly.\n",
    "Simple use cases include matching lower case strings with camelCase strings or matching\n",
    "floats with some precision threshold.\n",
    "\n",
    "Pathway standard library comes with a powerful `smart_fuzzy_join` functionality.\n",
    "This tutorial is a showcase of its capabilities. We will develop a Data Application which allows for fuzzy-joining\n",
    "two streams of data against each other, and also for maintaining audit entries and updating results on the fly - here is a sneak preview.\n",
    "\n",
    "![Demo animation](/assets/content/showcases/fuzzy_join/demo.gif)\n",
    "\n",
    "## The data\n",
    "\n",
    "We will be doing the fuzzy-join between two datasets on money transfers’ banking logs.\n",
    "When doing banking or bookkeeping, this operation would be known as [reconciliation](https://en.wikipedia.org/w/index.php?title=Reconciliation_(accounting)&oldid=1100237463) of\n",
    "two sets of transactions records.\n",
    "One dataset comes in a perfectly organized format - csv, the other dataset consists of\n",
    "'human written' lines describing the transactions.\n",
    "\n",
    "\n",
    "Here are samples from the datasets:\n",
    "\n",
    " **Data sourced automatically from a bank feed, in 'standard' CSV format**\n",
    "\n",
    "|id    |date      |amount|recipient |sender        |recipient_acc_no            |sender_acc_no               |\n",
    "|------|----------|------|----------|--------------|----------------------------|----------------------------|\n",
    "|0     |2020-06-04|8946  |M. Perez  |Jessie Roberts|HU30186000000000000008280573|ES2314520000000006226902    |\n",
    "|1     |2014-08-06|8529  |C. Barnard|Mario Miller  |ES8300590000000002968016    |PL59879710390000000009681693|\n",
    "|2     |2017-01-22|5048  |S. Card   |James Paletta |PL65889200090000000009197250|PL46193013890000000009427616|\n",
    "|3     |2020-09-15|7541  |C. Baxter |Hector Haley  |PL40881800090000000005784046|DE84733500000003419377      |\n",
    "|4     |2019-05-25|3580  |L. Prouse |Ronald Adams  |PL44124061590000000008986827|SI54028570008259759         |\n",
    "\n",
    "\n",
    "The first dataset is sourced automatically from a bank feed. Every few seconds a new batch of transactions is saved to `transactions/formatA/batch_timestamp.csv`.\n",
    "\n",
    " **Transaction logs entered by hand**\n",
    "\n",
    "|id |description|\n",
    "|---|-----------|\n",
    "|0  |Received 8521 €  on 2014-08-07 by INTERNATIONAL interest payment from ??? to C. Barnard, recipient acc. no. 000002968016 by BANCO DE MADRID, amount EUR €, flat fee 8 € |\n",
    "|1  |EUR 8944 on 2020-06-06 by INTERNATIONAL transfer credited to 00000000008280573 (M. Perez) by BNP Paribas Securities Services,  fee EUR 2, amount EUR 8946. |\n",
    "|2  |Finally got 5M quid on 2017-01-23 by DOMESTIC payment from Sergio Marquina to Bella Ciao, r. acc. 0000000009197250, oryg. amount 5_000_048, fees 5 quid. |\n",
    "|3  |3578 EUR am 2019-05-25 von INTERNATIONAL dividend payment by Pathway Inc. an L. Prouse, Empfängerkonto 8986827, Betrag 3580 EUR |\n",
    "|4  |Received 7540 EUR on 2020-09-15. Invoice, recipient C. Baxter, 0000000005784046, amount EUR 7541, fees EUR 1 |\n",
    "\n",
    "\n",
    "As you can see, it seems that each entry in the first dataset (data sourced automatically) has a corresponding entry in the other dataset (transaction logs entered by hand).\n",
    "In this example we will use the `smart_fuzzy_join` function from Pathway's standard library to make sure all is correctly matched.\n",
    "\n",
    "## What are we going to obtain?\n",
    "We want to obtain a table in which the matchings are expressed, e.g. the entry 0 for the first table corresponds to the entry 1 in the second table.\n",
    "In addition, we will include the confidence, a number expressing how confident we are in the matching.\n",
    "\n",
    "## Code\n",
    "First things first - imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pathway as pw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike on the showcase on our website, we cannot to rely on csv files here, so we provide directly the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactionsA = pd.DataFrame(\n",
    "                {\n",
    "                    'Unnamed: 0': [0, 1, 2, 3, 4],\n",
    "                    'date': [\n",
    "                        '2020-06-04',\n",
    "                        '2014-08-06',\n",
    "                        '2017-01-22',\n",
    "                        '2020-09-15',\n",
    "                        '2019-05-25'\n",
    "                    ],\n",
    "                    'amount': [8946,8529,5048,7541,3580],\n",
    "                    'recipient': [\n",
    "                        'M. Perez',\n",
    "                        'C. Barnard',\n",
    "                        'S. Card',\n",
    "                        'C. Baxter',\n",
    "                        'L. Prouse'\n",
    "                    ],\n",
    "                    'sender': [\n",
    "                        'Jessie Roberts',\n",
    "                        'Mario Miller',\n",
    "                        'James Paletta',\n",
    "                        'Hector Haley',\n",
    "                        'Ronald Adams'\n",
    "                    ],\n",
    "                    'recipient_acc_no': [\n",
    "                        'HU30186000000000000008280573',\n",
    "                        'ES8300590000000002968016',\n",
    "                        'PL65889200090000000009197250',\n",
    "                        'PL40881800090000000005784046',\n",
    "                        'PL44124061590000000008986827'\n",
    "                    ],\n",
    "                    'sender': [\n",
    "                        'ES2314520000000006226902',\n",
    "                        'PL59879710390000000009681693',\n",
    "                        'PL46193013890000000009427616',\n",
    "                        'DE84733500000003419377',\n",
    "                        'SI54028570008259759'\n",
    "                    ]\n",
    "                }\n",
    ")\n",
    "transactionsB = pd.DataFrame(\n",
    "                {\n",
    "                    'Unnamed: 0': [0, 1, 2, 3, 4],\n",
    "                    'description': [\n",
    "                        'Received EUR 8521 on 2014-08-07 by INTERNATIONAL interest from M. Miller to C. Barnard, recipient account 000002968016 by BANCO DE MADRID, amount EUR 8529, fees EUR 8',\n",
    "                        'Received EUR 8944 on 2020-06-06 by INTERNATIONAL transaction from J. Roberts to M. Perez, recipient account 00000000008280573 by BNP Paribas Securities Services, amount EUR 8946, fees EUR 2',\n",
    "                        'Received EUR 5043 on 2017-01-23 by DOMESTIC payment from J. Paletta to S. Card, recipient account 0000000009197250 by None, amount EUR 5048, fees EUR 5',\n",
    "                        'Received EUR 3578 on 2019-05-25 by INTERNATIONAL dividend from R. Adams to L. Prouse, recipient account 0000000008986827 by None, amount EUR 3580, fees EUR 2',\n",
    "                        'Received EUR 7540 on 2020-09-15 by INTERNATIONAL invoice from H. Haley to C. Baxter, recipient account 0000000005784046 by None, amount EUR 7541, fees EUR 1'\n",
    "                    ]\n",
    "                }\n",
    ")\n",
    "transactionsA = pw.debug.table_from_pandas(transactionsA, unsafe_trusted_ids=True)\n",
    "transactionsB = pw.debug.table_from_pandas(transactionsB, unsafe_trusted_ids=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this demonstration we will simply print a table with matchings found on the data sample presented above.\n",
    "But the code below works also in a production environment. In production:\n",
    "- All csv files will be dynamically ingested from these directories in their order of appearance.\n",
    "- The output will be updated immediately as new data appears at input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def match_transactions(transactionsA, transactionsB):\n",
    "    matching = pw.ml.smart_table_ops.fuzzy_match_tables(transactionsA, transactionsB)\n",
    "    transactionsA_reconciled = (\n",
    "        pw.Table.empty(left=pw.Pointer, right=pw.Pointer, confidence=float)\n",
    "        .update_rows(transactionsA.select(left=None, right=None, confidence=0.0))\n",
    "        .update_rows(\n",
    "            matching.select(\n",
    "                matching.left, matching.right, confidence=matching.weight\n",
    "            ).with_id(matching.left)\n",
    "        )\n",
    "    )\n",
    "    return transactionsA_reconciled\n",
    "\n",
    "\n",
    "def reconcile_transactions(transactionsA, transactionsB):\n",
    "    transactionsA_reconciled = match_transactions(transactionsA, transactionsB)\n",
    "    return transactionsA_reconciled\n",
    "\n",
    "\n",
    "pw.debug.compute_and_print(reconcile_transactions(transactionsA, transactionsB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success, all matchings were found!\n",
    "\n",
    "Super easy, few lines of code and you flawlessly manage datasets in different formats.\n",
    "Hassle-free.\n",
    "\n",
    "## Scaling with Pathway\n",
    "\n",
    "`smart_fuzzy_join` is able to handle much bigger datasets.\n",
    "Feel free to test it on your own data or use the full datasets from this tutorial,\n",
    "available [in this Google Spreadsheet](https://docs.google.com/spreadsheets/d/1cXAPcmkq0t0ieIQCBrdKPG2Fq_DimAzzxfHsDWrtdW0/edit?usp=sharing).\n",
    "\n",
    "<!-- It took TODO seconds to run the `match_formats` on the full datasets TODO rows each. -->\n",
    "\n",
    "In the tutorial we just printed a matching found on a small data sample. In a dynamic production environment:\n",
    "- All csv files will be dynamically ingested from these directories in order of appearance.\n",
    "- **The output will be updated immediately as new data appears at input.**\n",
    "\n",
    "## Conclusion and follow-up tasks\n",
    "\n",
    "While errors are human and we are unlikely to stop making some, we can free ourselves of the pain of correcting them each time something goes wrong.\n",
    "Sometimes, entries are harder to match and may require help: in that case you can check out our [extension](/developers/showcases/fuzzy_join/fuzzy_join_chapter2) and see how we extend our pipeline with an auditor that supervises the process of reconciliation.\n",
    "From now on, you have no excuses for having mismatching logs: 'errare humanum est, perseverare diabolicum'!\n",
    "\n",
    "\n",
    "If you would like to get some more experience with Pathway, you can try those two challenges:\n",
    "\n",
    "**Challenge 1**\n",
    "\n",
    "Extend the `match_transactions` function so that, after finding a matching, it extends the first input table (standard csv format) with columns 'fees' and 'currency'.\n",
    "\n",
    "**Challenge 2**\n",
    "\n",
    "Try to augment the datasets so that they are still reasonable but `smart_fuzzy_join` fails to find all matchings 😉"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
